{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "84c09591",
   "metadata": {},
   "source": [
    "### Building A chatbot\n",
    "\n",
    "In this we will cover an example of how to design and implement an LLM-powered chatbot. This chatbot will be able to have a conversation and remeber previous interactions.\n",
    "\n",
    "Note that this chatbot that we build will only use the language model to have a conversation.There are several other related concepts that you may be looking for:\n",
    "\n",
    "* Convrsational RAG: Enable a chatbot experience over an external source of data.\n",
    "\n",
    "* Agents: Build a chatbot that can take actions\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "d28b9ce3",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from dotenv import load_dotenv\n",
    "load_dotenv()\n",
    "\n",
    "groq_api_key= os.getenv('GROQ_API_KEY')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "f81cbbff",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ChatGroq(client=<groq.resources.chat.completions.Completions object at 0x00000237CFA56990>, async_client=<groq.resources.chat.completions.AsyncCompletions object at 0x00000237CFA57750>, model_name='Gemma2-9b-It', model_kwargs={}, groq_api_key=SecretStr('**********'))"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from langchain_groq import ChatGroq\n",
    "model= ChatGroq(model=\"Gemma2-9b-It\",groq_api_key=groq_api_key)\n",
    "model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "13a29b08",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AIMessage(content=\"Hello Neha, it's a pleasure to meet you!\\n\\nThat's an impressive title. As a chief AI engineer, I imagine you're doing some fascinating work. \\n\\nWhat are you currently working on that you're most excited about?\\n\", additional_kwargs={}, response_metadata={'token_usage': {'completion_tokens': 56, 'prompt_tokens': 22, 'total_tokens': 78, 'completion_time': 0.101818182, 'prompt_time': 0.001337519, 'queue_time': 0.256282352, 'total_time': 0.103155701}, 'model_name': 'Gemma2-9b-It', 'system_fingerprint': 'fp_10c08bf97d', 'service_tier': 'on_demand', 'finish_reason': 'stop', 'logprobs': None}, id='run--53b08180-2b7b-4b6a-a182-3ea822f928e5-0', usage_metadata={'input_tokens': 22, 'output_tokens': 56, 'total_tokens': 78})"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from langchain_core.messages import HumanMessage\n",
    "model.invoke([HumanMessage(content=\"Hi My name is Neha and I am a chief AI engineer\")])\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "97d736e0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AIMessage(content=\"You said your name is Neha and that you are a chief AI engineer.  \\n\\nIs there anything else you'd like to tell me about yourself or your work? I'm eager to learn more! üòä  \\n\\n\", additional_kwargs={}, response_metadata={'token_usage': {'completion_tokens': 49, 'prompt_tokens': 107, 'total_tokens': 156, 'completion_time': 0.089090909, 'prompt_time': 0.002760098, 'queue_time': 0.255034627, 'total_time': 0.091851007}, 'model_name': 'Gemma2-9b-It', 'system_fingerprint': 'fp_10c08bf97d', 'service_tier': 'on_demand', 'finish_reason': 'stop', 'logprobs': None}, id='run--3478c490-db2e-4fb8-89dd-18c2da03c431-0', usage_metadata={'input_tokens': 107, 'output_tokens': 49, 'total_tokens': 156})"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from langchain_core.messages import AIMessage\n",
    "\n",
    "model.invoke(\n",
    "    [\n",
    "        HumanMessage(content=\"Hi My name is Neha and I am a chief AI engineer\"),\n",
    "        AIMessage(content=\"Hello Neha, it's nice to meet you!\\n\\nThat's a fantastic role. As a large language model, I'm always interested in learning more about the work that AI engineers do.\\n\\nWhat kind of projects are you currently working on?  \\n\\nI hope you have a productive day!\\n\"),\n",
    "        HumanMessage(content=\"What's my name and what do i do?\")\n",
    "    ]\n",
    ")\n",
    "# first of all we are fieding the information and asking it again toi check whether it is remebering my name. hence it is saving the message history"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8664afcf",
   "metadata": {},
   "source": [
    "### Message History\n",
    "\n",
    "We can use a Message history class to wrap our model and make it stateful. this will keep track of inputs and outputs of the model and store them in some datastore. Future interactions will then load those messages and pass them into the chain as part of the input. Let's see how to use this!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "1f60281b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_community.chat_message_histories import ChatMessageHistory\n",
    "from langchain_core.chat_history import BaseChatMessageHistory\n",
    "from langchain_core.runnables.history import RunnableWithMessageHistory\n",
    "\n",
    "# for understanding the history of the particular user we define this function so that the llm can understand when used by multiple user at a time\n",
    "\n",
    "store={}\n",
    "\n",
    "def get_session_history(session_id:str)->BaseChatMessageHistory:\n",
    "    if session_id not in store:\n",
    "        store[session_id]=ChatMessageHistory()\n",
    "    return store[session_id]\n",
    "\n",
    "with_message_history=RunnableWithMessageHistory(model,get_session_history)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "06a0398f",
   "metadata": {},
   "outputs": [],
   "source": [
    "config={\"configurable\":{\"session_id\":\"chat1\"}}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "cb0d6660",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"Hello Neha! It's nice to meet you.\\n\\nThat's a fantastic title! As a large language model, I'm always interested in learning more about the work of AI engineers.  \\n\\nWhat are you currently working on that you're excited about?\\n\""
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "response=with_message_history.invoke(\n",
    "    [HumanMessage(content=\"Hi My name is Neha and I am a chief AI engineer\")],\n",
    "    config=config\n",
    ")\n",
    "response.content"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "f1f8b550",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Your name is Neha, as you told me at the beginning of our conversation. üòä  \\n\\nIs there anything else I can help you with?\\n'"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "response=with_message_history.invoke(\n",
    "    [HumanMessage(content=\"What is my name\")],\n",
    "    config=config\n",
    ")\n",
    "response.content"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b1550fa1",
   "metadata": {},
   "source": [
    "#### changing the config (session_id) to check whether it remenbers the name or not"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "f5abae83",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'You told me your name is Neha!  \\n\\nIs there something else I can help you with?\\n'"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "config1={\"configurable\":{\"session_id\":\"chat1\"}}\n",
    "response=with_message_history.invoke(\n",
    "    [HumanMessage(content=\"What is my name\")],\n",
    "    config=config1\n",
    ")\n",
    "response.content"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "fdb145af",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"As an AI, I have no memory of past conversations and do not know your name. If you'd like to tell me, I'm happy to know! üòä\\n\""
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# in abpve we are getting the response because the session_id is same\n",
    "# let's change it and then check\n",
    "config1={\"configurable\":{\"session_id\":\"chat2\"}}\n",
    "response=with_message_history.invoke(\n",
    "    [HumanMessage(content=\"What is my name\")],\n",
    "    config=config1\n",
    ")\n",
    "response.content"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "986bbf12",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"Hi Sharma, it's nice to meet you! üòä \\n\\nIs there anything I can help you with today?\\n\""
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "response=with_message_history.invoke(\n",
    "    [HumanMessage(content=\"Hey My name is Sharma\")],\n",
    "    config=config1\n",
    ")\n",
    "response.content"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "6e8b04ab",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Your name is Sharma.  \\n\\nI remember! üòÑ  Is there anything else I can help you with?\\n'"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "response=with_message_history.invoke(\n",
    "    [HumanMessage(content=\"What is my name\")],\n",
    "    config=config1\n",
    ")\n",
    "response.content"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "31e68adb",
   "metadata": {},
   "source": [
    "### Prompt templates\n",
    "\n",
    "These help to turn raw user information into a fromat that the LLM can work with. In this case, the raw user input is just a message, which we are passing to the LLM. Let's now make that a bit more complicated. first let's add in a system message with some custom instructions (but still taking messages as input). Next, we'll add in more input besides just the messages."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "943e4721",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_core.prompts import ChatPromptTemplate,MessagesPlaceholder\n",
    "\n",
    "prompt=ChatPromptTemplate(\n",
    "    [\n",
    "        (\"system\",\"You are a helpful AI assistant. Answer all the questions to the best of your ability\"),\n",
    "        MessagesPlaceholder(variable_name=\"messages\")\n",
    "\n",
    "    ]\n",
    ")\n",
    "\n",
    "chain=prompt|model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "0b7c1979",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AIMessage(content=\"Hi Neha! It's nice to meet you. \\n\\nWhat can I do for you today? üòä  \\n\\n\", additional_kwargs={}, response_metadata={'token_usage': {'completion_tokens': 28, 'prompt_tokens': 32, 'total_tokens': 60, 'completion_time': 0.050909091, 'prompt_time': 0.001505029, 'queue_time': 0.254953621, 'total_time': 0.05241412}, 'model_name': 'Gemma2-9b-It', 'system_fingerprint': 'fp_10c08bf97d', 'service_tier': 'on_demand', 'finish_reason': 'stop', 'logprobs': None}, id='run--f201eaa4-c5b0-42e3-bb32-1daddf548f3a-0', usage_metadata={'input_tokens': 32, 'output_tokens': 28, 'total_tokens': 60})"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "chain.invoke({\"messages\":[HumanMessage(content=\"Hi my name is neha\")]})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "d20acbee",
   "metadata": {},
   "outputs": [],
   "source": [
    "with_message_history=RunnableWithMessageHistory(chain,get_session_history)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "95325ff6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"Hello Neha, it's nice to meet you! \\n\\nHow can I help you today? üòä  \\n\\n\""
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "config= {\"configurable\": {\"session_id\":\"chat3\"}}\n",
    "response=with_message_history.invoke(\n",
    "    [HumanMessage(content=\"Hi My name is Neha\")],\n",
    "    config=config\n",
    ")\n",
    "response.content"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "ec4cc433",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Add more complexity\n",
    "\n",
    "prompt=ChatPromptTemplate(\n",
    "    [\n",
    "        (\"system\",\"You are a helpful AI assistant. Answer all the questions to the best of your ability in {bhasha}\"),\n",
    "        MessagesPlaceholder(variable_name=\"msg\")\n",
    "\n",
    "    ]\n",
    ")\n",
    "chain=prompt|model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "407db3bf",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'‡§®‡§Æ‡§∏‡•ç‡§§‡•á ‡§®‡•Ä‡§π‡§æ!  \\n\\n‡§Æ‡•à‡§Ç ‡§Ü‡§™‡§ï‡•Ä ‡§Æ‡§¶‡§¶ ‡§ï‡§∞‡§®‡•á ‡§ï‡•á ‡§≤‡§ø‡§è ‡§Ø‡§π‡§æ‡§Å ‡§π‡•Ç‡§Å‡•§  ‡§Ü‡§™‡§ï‡•á ‡§ï‡•ã‡§à ‡§∏‡§µ‡§æ‡§≤ ‡§π‡•à‡§Ç? üòä  \\n'"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "response=chain.invoke({\"messages\":[HumanMessage(content=\"Hi My name is Neha\")], \"bhasha\":\"Hindi\"})\n",
    "response.content"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d43a487d",
   "metadata": {},
   "source": [
    "Let's now wrap this more complicated chain in a Message History class. This time, because there are multiple keys in the input, we need to specify the correct key to use to save the chat history."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "c8678a3c",
   "metadata": {},
   "outputs": [],
   "source": [
    "with_message_history=RunnableWithMessageHistory(\n",
    "    chain,\n",
    "    get_session_history,\n",
    "    input_messages_key=\"msg\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f755c633",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'‡§®‡§Æ‡§∏‡•ç‡§§‡•á ‡§®‡•á‡§π‡§æ! üòä \\n\\n‡§Ü‡§™ ‡§ï‡•à‡§∏‡•á ‡§π‡•à‡§Ç?  \\n'"
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "config={\"configurable\":{\"session_id\":\"chat4\"}}\n",
    "response=with_message_history.invoke(\n",
    "    {\"msg\":[HumanMessage(content=\"Hi i am neha\")],\"bhasha\":\"hindi\"},\n",
    "    config=config\n",
    ")\n",
    "response.content\n",
    "\n",
    "# so for input messages key we can set it to any thing but it should be similar in all prompt with msg and invoke"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9376bc64",
   "metadata": {},
   "source": [
    "### Manage the Conversation History"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0c2fa064",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
