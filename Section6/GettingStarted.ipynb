{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "6549e421",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from dotenv import load_dotenv\n",
    "load_dotenv(r\"C:\\Users\\neha.sharma\\Desktop\\Agentic_AI\\.env\",override=True)\n",
    "\n",
    "\n",
    "os.environ['OPENAI_API_KEY']=os.getenv(\"OPENAI_API_KEY\")\n",
    "# langsmith tracking\n",
    "os.environ['LANGCHAIN_API_KEY']=os.getenv(\"LANGCHAIN_API_KEY\")\n",
    "os.environ[\"LANGCHAIN_TRACING_V2\"]=\"true\"\n",
    "os.environ[\"LANGCHAIN_PROJECT\"]=os.getenv(\"LANGCHAIN_PROJECT\")\n",
    "# ai=os.getenv(\"OPENAI_API_KEY\")\n",
    "# print(ai)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "f92981c1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "client=<openai.resources.chat.completions.completions.Completions object at 0x0000023BC58E4E60> async_client=<openai.resources.chat.completions.completions.AsyncCompletions object at 0x0000023BC58E5130> root_client=<openai.OpenAI object at 0x0000023BC58E47D0> root_async_client=<openai.AsyncOpenAI object at 0x0000023BC58E4AA0> model_name='gpt-4o' model_kwargs={} openai_api_key=SecretStr('**********')\n"
     ]
    }
   ],
   "source": [
    "from langchain_openai import ChatOpenAI\n",
    "llm=ChatOpenAI(model=\"gpt-4o\",streaming=False)\n",
    "print(llm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "e51733eb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AIMessage(content='Generative AI, often abbreviated as Gen AI, refers to a type of artificial intelligence technology designed to generate content. This content can include text, images, music, and even video. Unlike traditional AI, which might classify or analyze existing data, generative AI creates new data. It does this using sophisticated models like generative adversarial networks (GANs) and transformer-based models such as GPT (Generative Pre-trained Transformer).\\n\\nKey applications of generative AI include:\\n\\n1. **Text Generation**: Tools like ChatGPT can generate human-like text based on input prompts, enabling applications in content creation, customer service, and more.\\n\\n2. **Image Generation**: Models like DALL-E and Stable Diffusion can create detailed images from textual descriptions.\\n\\n3. **Music and Video Production**: Generative AI is used in composing music by mimicking styles or generating entirely new compositions, as well as in video creation by generating animations or deepfake content.\\n\\n4. **Design and Art**: AI can assist artists and designers by generating ideas or finished pieces that may inspire or aid the creative process.\\n\\n5. **Data Augmentation**: In machine learning, generative AI can create synthetic data that helps in training models, especially where real data is scarce.\\n\\nGenerative AI has gained popularity due to its ability to innovate and produce human-quality content. However, ethical concerns about authenticity, privacy, and potential misuse also surround its applications.', additional_kwargs={'refusal': None}, response_metadata={'token_usage': {'completion_tokens': 288, 'prompt_tokens': 12, 'total_tokens': 300, 'completion_tokens_details': {'accepted_prediction_tokens': 0, 'audio_tokens': 0, 'reasoning_tokens': 0, 'rejected_prediction_tokens': 0}, 'prompt_tokens_details': {'audio_tokens': 0, 'cached_tokens': 0}}, 'model_name': 'gpt-4o-2024-08-06', 'system_fingerprint': 'fp_07871e2ad8', 'id': 'chatcmpl-BriMPsdRbWzSRcUHgFzTmfEMO615O', 'service_tier': 'default', 'finish_reason': 'stop', 'logprobs': None}, id='run--aeceee08-0ce9-40d8-a920-a74be98555da-0', usage_metadata={'input_tokens': 12, 'output_tokens': 288, 'total_tokens': 300, 'input_token_details': {'audio': 0, 'cache_read': 0}, 'output_token_details': {'audio': 0, 'reasoning': 0}})"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "##Input and get response from LLM\n",
    "\n",
    "res=llm.invoke(\"what is gen ai?\")\n",
    "res\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "5c42e06a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ChatPromptTemplate(input_variables=['input'], input_types={}, partial_variables={}, messages=[SystemMessagePromptTemplate(prompt=PromptTemplate(input_variables=[], input_types={}, partial_variables={}, template='You are an expert AI engineer. Provide me answers based on the question'), additional_kwargs={}), HumanMessagePromptTemplate(prompt=PromptTemplate(input_variables=['input'], input_types={}, partial_variables={}, template='{input}'), additional_kwargs={})])"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "### Chatprompt template\n",
    "from langchain_core.prompts import ChatPromptTemplate\n",
    "\n",
    "prompt =ChatPromptTemplate.from_messages(\n",
    "    [\n",
    "        (\"system\",\"You are an expert AI engineer. Provide me answers based on the question\"),\n",
    "        (\"user\",\"{input}\")\n",
    "    ]\n",
    ")\n",
    "prompt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "619c51a0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "content='LangSmith is a suite of tools and services designed to enhance the development and deployment of applications that use large language models (LLMs). It is part of the LangChain ecosystem, which focuses on providing infrastructure and utilities for managing and interacting with LLMs and AI models in general.\\n\\nLangSmith offers several key features:\\n\\n1. **Monitoring and Observability:** It allows developers to monitor the performance of their language models in real time. This includes tracking metrics such as latency, error rates, and usage patterns, which can help in identifying issues and optimizing the performance of applications leveraging LLMs.\\n\\n2. **Evaluation:** LangSmith provides tools to evaluate the performance and behavior of language models. This helps developers understand how well their models are performing, identify potential areas for improvement, and ensure that the models are meeting the desired requirements and benchmarks.\\n\\n3. **Dataset Management:** It includes features for managing datasets that are used for training and fine-tuning language models. This is crucial for maintaining high-quality input data, which directly impacts the effectiveness of the models.\\n\\n4. **Infrastructure Support:** As part of the LangChain framework, LangSmith supports the integration and orchestration of various components needed to build applications that utilize LLMs. This includes connecting to different models, managing API communications, and scaling deployments.\\n\\nThese capabilities make LangSmith a valuable tool for developers who want to build, deploy, and maintain applications powered by language models while ensuring efficiency, reliability, and high performance.' additional_kwargs={'refusal': None} response_metadata={'token_usage': {'completion_tokens': 295, 'prompt_tokens': 33, 'total_tokens': 328, 'completion_tokens_details': {'accepted_prediction_tokens': 0, 'audio_tokens': 0, 'reasoning_tokens': 0, 'rejected_prediction_tokens': 0}, 'prompt_tokens_details': {'audio_tokens': 0, 'cached_tokens': 0}}, 'model_name': 'gpt-4o-2024-08-06', 'system_fingerprint': None, 'id': 'chatcmpl-BriMwNHb8sr2jOyu984rb9g4xLexz', 'service_tier': 'default', 'finish_reason': 'stop', 'logprobs': None} id='run--aca9b971-1c29-4ef6-b811-2c062928a032-0' usage_metadata={'input_tokens': 33, 'output_tokens': 295, 'total_tokens': 328, 'input_token_details': {'audio': 0, 'cache_read': 0}, 'output_token_details': {'audio': 0, 'reasoning': 0}}\n"
     ]
    }
   ],
   "source": [
    "# chain is combining prompt llm and how the flow is\n",
    "\n",
    "chain=prompt|llm\n",
    "response=chain.invoke({\"input\":\"Can you tell me about langsmith?\"})\n",
    "print(response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "502981a5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "langchain_core.messages.ai.AIMessage"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "c53bbbcd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "LangSmith is a tool developed by LangChain designed to assist in the development and evaluation of language model applications. It offers features for tracing, analyzing, debugging, and testing LLM (Large Language Models) applications at scale. With LangSmith, developers and teams can gain insights into how their applications perform and identify areas for improvement, enabling more efficient and effective development processes. The focus is on providing a robust infrastructure to manage and optimize language model interactions.\n"
     ]
    }
   ],
   "source": [
    "# output parser -- stroutput parser  also we can create our own\n",
    "\n",
    "from langchain_core.output_parsers import StrOutputParser\n",
    "output_parser=StrOutputParser()\n",
    "print(output_parser)\n",
    "chain=prompt|llm|output_parser\n",
    "\n",
    "response=chain.invoke({\"input\":\"Can you tell me about langsmith?\"})\n",
    "print(response)\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
